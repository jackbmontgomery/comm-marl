@article{zhu2024survey,
  title={A survey of multi-agent deep reinforcement learning with communication},
  author={Zhu, Changxi and Dastani, Mehdi and Wang, Shihan},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={38},
  number={1},
  pages={4},
  year={2024},
  publisher={Springer}
}
@misc{pina2024fully,
      title={Fully Independent Communication in Multi-Agent Reinforcement Learning}, 
      author={Rafael Pina and Varuna De Silva and Corentin Artaud and Xiaolan Liu},
      year={2024},
      eprint={2401.15059},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.15059}, 
}

@article{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{sukhbaatar2016commnet,
  title={Learning multiagent communication with backpropagation},
  author={Sukhbaatar, Sainbayar and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{
singh2018ic3net,
title={Individualized Controlled Continuous Communication Model for Multiagent Cooperative and Competitive Tasks},
author={Amanpreet Singh and Tushar Jain and Sainbayar Sukhbaatar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rye7knCqK7},
}

@article{peng2017bicnet,
author = {Peng, Peng and Yuan, Quan and Wen, Ying and Yang, Yaodong and Tang, Zhenkun and Long, Haitao and Wang, Jun},
year = {2017},
month = {03},
pages = {},
title = {Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games},
doi = {10.48550/arXiv.1703.10069}
}

@inproceedings{chu2020NeurComm,
title={Multi-agent Reinforcement Learning for Networked System Control},
author={Tianshu Chu and Sandeep Chinchali and Sachin Katti},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Syx7A3NFvH}
}

@misc{gupta2022HAMMER,
  title = {{{HAMMER}}: {{Multi-Level Coordination}} of {{Reinforcement Learning Agents}} via {{Learned Messaging}}},
  shorttitle = {{{HAMMER}}},
  author = {Gupta, Nikunj and Srinivasaraghavan, G. and Mohalik, Swarup Kumar and Kumar, Nishant and Taylor, Matthew E.},
  year = {2022},
  month = dec,
  number = {arXiv:2102.00824},
  eprint = {2102.00824},
  publisher = {arXiv},
  urldate = {2024-10-30},
  abstract = {Cooperative multi-agent reinforcement learning (MARL) has achieved significant results, most notably by leveraging the representation-learning abilities of deep neural networks. However, large centralized approaches quickly become infeasible as the number of agents scale, and fully decentralized approaches can miss important opportunities for information sharing and coordination. Furthermore, not all agents are equal -- in some cases, individual agents may not even have the ability to send communication to other agents or explicitly model other agents. This paper considers the case where there is a single, powerful, {\textbackslash}emph\{central agent\} that can observe the entire observation space, and there are multiple, low-powered {\textbackslash}emph\{local agents\} that can only receive local observations and are not able to communicate with each other. The central agent's job is to learn what message needs to be sent to different local agents based on the global observations, not by centrally solving the entire problem and sending action commands, but by determining what additional information an individual agent should receive so that it can make a better decision. In this work we present our MARL algorithm {\textbackslash}algo, describe where it would be most applicable, and implement it in the cooperative navigation and multi-agent walker domains. Empirical results show that 1) learned communication does indeed improve system performance, 2) results generalize to heterogeneous local agents, and 3) results generalize to different reward structures.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Multiagent Systems},
  file = {/Users/jackmontgomery/Zotero/storage/U3CHA6MY/Gupta et al. - 2022 - HAMMER Multi-Level Coordination of Reinforcement Learning Agents via Learned Messaging.pdf;/Users/jackmontgomery/Zotero/storage/UWFQH7NW/2102.html}
}
