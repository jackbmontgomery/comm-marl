_wandb:
    value:
        cli_version: 0.18.6
        m: []
        python_version: 3.10.0
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 2
                - 16
                - 23
                - 55
            "4": 3.10.0
            "5": 0.18.6
            "8":
                - 5
            "12": 0.18.6
            "13": darwin-arm64
alg:
    value: idql
anneal_epsilon:
    value: 1.8999999999999998e-05
batch_size:
    value: 32
buffer_size:
    value: 5000
comm_net_dim:
    value: 64
cuda_device:
    value: 0
env:
    value: PredatorPrey
episode_limit:
    value: 100
epsilon:
    value: 1
epsilon_anneal_scale:
    value: step
evaluate_cycle:
    value: 10000
evaluate_epoch:
    value: 20
final_msg_dim:
    value: 10
gamma:
    value: 0.99
grad_norm_clip:
    value: 10
last_action:
    value: true
learn:
    value: true
load_model:
    value: false
lr:
    value: 0.0005
min_epsilon:
    value: 0.05
model_dir:
    value: ./model
msg_cut:
    value: false
n_actions:
    value: 5
n_agents:
    value: 4
n_episodes:
    value: 1
n_steps:
    value: 1000
obs_shape:
    value: 28
optimizer:
    value: RMS
parameter_sharing:
    value: false
result_dir:
    value: ./result
reuse_network:
    value: true
rnn_hidden_dim:
    value: 64
save_cycle:
    value: 6650
state_shape:
    value: 112
target_update_cycle:
    value: 200
train_steps:
    value: 1
with_comm:
    value: false
